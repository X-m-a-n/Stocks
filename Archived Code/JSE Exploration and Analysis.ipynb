{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Machine Learning Algorithms Potential to Predict Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "#import ta\n",
    "import ta_py as ta\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    \"\"\"Create technical indicators and prepare features\"\"\"\n",
    "    # Convert polars series to numpy arrays for ta_py\n",
    "    closing_prices = df['closing_price'].to_numpy()\n",
    "    high_prices = df['daily_range_high'].to_numpy()\n",
    "    low_prices = df['daily_range_low'].to_numpy()\n",
    "    volumes = df['volume'].to_numpy()\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    indicators = pl.DataFrame({\n",
    "        'sma_20': ta.sma(closing_prices, 20),\n",
    "        'sma_50': ta.sma(closing_prices, 50),\n",
    "        'macd': ta.macd(closing_prices, 12, 26),\n",
    "        'rsi': ta.rsi(closing_prices, 14),\n",
    "        'stoch': ta.stoch([high_prices, closing_prices, low_prices],  14)\n",
    "        #'bb': ta.fibbands(closing_prices, 20, 2),\n",
    "        #'bb_low': ta.bbands_lower(closing_prices, 20, 2),\n",
    "        #'vpt': ta.pvt(closing_prices, volumes)  # Price Volume Trend\n",
    "    })\n",
    "    \n",
    "    # Convert indicators back to polars and add to original dataframe\n",
    "    for col in indicators.columns:\n",
    "        df = df.with_columns([\n",
    "            pl.Series(name=col, values=indicators[col])\n",
    "        ])\n",
    "    \n",
    "    # Calculate returns using polars\n",
    "    df = df.with_columns([\n",
    "        pl.col('closing_price').pct_change().alias('returns')\n",
    "    ])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, symbol):\n",
    "    \"\"\"Train prediction model for a given stock symbol\"\"\"\n",
    "    # Filter data for symbol\n",
    "    stock_df = df.filter(pl.col('symbol') == symbol)\n",
    "    \n",
    "    # Prepare features\n",
    "    stock_df = prepare_features(stock_df)\n",
    "    \n",
    "    # Define features and target\n",
    "    features = ['sma_20', 'sma_50', 'macd', 'rsi', 'stoch', \n",
    "               'bb_high', 'bb_low', 'vpt', 'volume']\n",
    "    target = 'returns'\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    stock_df = stock_df.drop_nulls()\n",
    "    \n",
    "    # Split into features and target\n",
    "    X = stock_df.select(features).to_numpy()\n",
    "    y = stock_df.select(target).to_numpy().ravel()\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize model \n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train using time series split\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(X_scaled):\n",
    "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_val)\n",
    "        score = mean_squared_error(y_val, pred, squared=False)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print(f\"Average RMSE: {np.mean(scores):.4f}\")\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_signals(model, scaler, current_data):\n",
    "    \"\"\"Generate trading signals based on model predictions\"\"\"\n",
    "    X = current_data.select(features).to_numpy()\n",
    "    X_scaled = scaler.transform(X)\n",
    "    pred_returns = model.predict(X_scaled)\n",
    "    \n",
    "    # Generate signals based on predicted returns\n",
    "    signals = np.where(pred_returns > 0.01, 1,  # Buy signal\n",
    "                      np.where(pred_returns < -0.01, -1, 0))  # Sell signal\n",
    "    \n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_data(data_folder):\n",
    "    \"\"\"\n",
    "    Load all stock data files from a folder into a single dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    data_folder (str): Path to folder containing stock data files\n",
    "    \n",
    "    Returns:\n",
    "    polars.DataFrame: Combined stock data\n",
    "    \"\"\"\n",
    "    # Get all CSV files in folder\n",
    "    data_path = pathlib.Path(data_folder)\n",
    "    data_files = list(data_path.glob('*.csv'))\n",
    "    \n",
    "    if not data_files:\n",
    "        raise ValueError(f\"No CSV files found in {data_folder}\")\n",
    "        \n",
    "    # Read and combine all files\n",
    "    dfs = []\n",
    "    for file in data_files:\n",
    "        try:\n",
    "            df = pl.read_csv(\n",
    "                file,\n",
    "                try_parse_dates=True,\n",
    "                columns=[\n",
    "                    'date', 'symbol', 'last_price', 'closing_price', \n",
    "                    'price_change', 'bid', 'ask', 'volume', 'daily_range_low', 'daily_range_high', 'year_range_low',\n",
    "                    'year_range_high'\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Convert columns to appropriate types\n",
    "            df = df.with_columns([\n",
    "                pl.col(['last_price', 'closing_price', 'price_change', 'bid', 'ask', \n",
    "                       'daily_range_low', 'daily_range_high', 'year_range_low', 'year_range_high']).cast(pl.Float64),\n",
    "                pl.col('volume').cast(pl.Int64)\n",
    "                #pl.col('date').str.strptime(pl.Date, format = '%d/%m/%Y')\n",
    "            ])\n",
    "            \n",
    "            dfs.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No valid data files could be processed\")\n",
    "        \n",
    "    # Combine all dataframes\n",
    "    combined_df = pl.concat(dfs)\n",
    "    \n",
    "    # Sort by date and symbol\n",
    "    combined_df = combined_df.sort(['date', 'symbol'])\n",
    "    \n",
    "    # Drop original range columns\n",
    "    #combined_df = combined_df.drop(['range', 'year_range'])\n",
    "    \n",
    "    print(f\"Loaded {len(data_files)} files with {len(combined_df)} total rows\")\n",
    "    print(f\"Date range: {combined_df['date'].min()} to {combined_df['date'].max()}\")\n",
    "    print(f\"Unique symbols: {len(combined_df['symbol'].unique())}\")\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2753 files with 557308 total rows\n",
      "Date range: 2014-01-02 to 2024-12-24\n",
      "Unique symbols: 294\n"
     ]
    },
    {
     "ename": "ShapeError",
     "evalue": "could not create a new DataFrame: series 3835 has length 3835 while series \"sma_50\" has length 3805",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mShapeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Usage example:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m load_stock_data(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmichaelsjo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mStocks\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meod_trade_summary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNCBFG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m signals \u001b[38;5;241m=\u001b[39m predict_signals(model, scaler, current_data)\n",
      "Cell \u001b[1;32mIn[107], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(df, symbol)\u001b[0m\n\u001b[0;32m      4\u001b[0m stock_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m symbol)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Prepare features\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m stock_df \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define features and target\u001b[39;00m\n\u001b[0;32m     10\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msma_20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msma_50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrsi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstoch\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     11\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb_high\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb_low\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[106], line 10\u001b[0m, in \u001b[0;36mprepare_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m volumes \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate technical indicators\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m indicators \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msma_20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosing_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msma_50\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosing_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmacd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosing_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrsi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosing_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhigh_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosing_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_prices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#'bb': ta.fibbands(closing_prices, 20, 2),\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#'bb_low': ta.bbands_lower(closing_prices, 20, 2),\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#'vpt': ta.pvt(closing_prices, volumes)  # Price Volume Trend\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert indicators back to polars and add to original dataframe\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m indicators\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\michaelsjo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\polars\\dataframe\\frame.py:367\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, schema, schema_overrides, strict, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m dict_to_pydf(\n\u001b[0;32m    363\u001b[0m         {}, schema\u001b[38;5;241m=\u001b[39mschema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides\n\u001b[0;32m    364\u001b[0m     )\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_pydf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, Sequence)):\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m sequence_to_pydf(\n\u001b[0;32m    377\u001b[0m         data,\n\u001b[0;32m    378\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m         infer_schema_length\u001b[38;5;241m=\u001b[39minfer_schema_length,\n\u001b[0;32m    383\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\michaelsjo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\polars\\_utils\\construction\\dataframe.py:170\u001b[0m, in \u001b[0;36mdict_to_pydf\u001b[1;34m(data, schema, schema_overrides, strict, nan_to_null, allow_multithreaded)\u001b[0m\n\u001b[0;32m    159\u001b[0m     data_series \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    160\u001b[0m         s\u001b[38;5;241m.\u001b[39m_s\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m _expand_dict_values(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m         )\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    167\u001b[0m     ]\n\u001b[0;32m    169\u001b[0m data_series \u001b[38;5;241m=\u001b[39m _handle_columns_arg(data_series, columns\u001b[38;5;241m=\u001b[39mcolumn_names, from_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 170\u001b[0m pydf \u001b[38;5;241m=\u001b[39m \u001b[43mPyDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_series\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema_overrides \u001b[38;5;129;01mand\u001b[39;00m pydf\u001b[38;5;241m.\u001b[39mdtypes() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(schema_overrides\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    173\u001b[0m     pydf \u001b[38;5;241m=\u001b[39m _post_apply_columns(\n\u001b[0;32m    174\u001b[0m         pydf, column_names, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[0;32m    175\u001b[0m     )\n",
      "\u001b[1;31mShapeError\u001b[0m: could not create a new DataFrame: series 3835 has length 3835 while series \"sma_50\" has length 3805"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "df = load_stock_data(r'C:\\Users\\michaelsjo\\Desktop\\Stocks\\Data\\eod_trade_summary')\n",
    "model, scaler = train_model(df, 'NCBFG')\n",
    "signals = predict_signals(model, scaler, current_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
