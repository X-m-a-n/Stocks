{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88c7e0c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tools/Utilities\n",
    "from pathlib import Path\n",
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta, date\n",
    "from typing import List, Tuple, Dict\n",
    "import buckaroo\n",
    "import gc\n",
    "import talib\n",
    "# Custom Imports\n",
    "from data_loader import DataLoader\n",
    "from technical_indicators import add_all_indicators, filter_buy_signals, get_signals_summary\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b27c0",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "566bd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    trade_date as date,\n",
    "    clean_symbol as symbol,\n",
    "    -- open_price,\n",
    "    daily_range_high as high,\n",
    "    daily_range_low as low,\n",
    "    closing_price as close,\n",
    "    closing_price + price_change as open,\n",
    "    volume\n",
    "FROM\n",
    "\told_trade_data TD\n",
    "    LEFT JOIN  jse_database.instruments I on (TD.CLEAN_symbol = I.symbol AND TD.CURRENCY = I.CURRENCY)\n",
    "WHERE\n",
    "    trade_date BETWEEN :start_date AND :end_date\n",
    "    AND I.TYPE = 'ORDINARY'\n",
    "    AND TD.CURRENCY = 'JMD'\n",
    "ORDER BY\n",
    "\ttrade_date ASC,\n",
    "\tclean_symbol ASC\n",
    "\"\"\"\n",
    "\n",
    "# Load all stocks data\n",
    "df = loader.fetch_data(\n",
    "    query=query,\n",
    "    start_date='2017-01-01',\n",
    "    end_date='2025-03-31'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2250774",
   "metadata": {},
   "source": [
    "# Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4b470",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6080a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05f70c",
   "metadata": {},
   "source": [
    "# Sentiment Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d9b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63749c64d9d0447781d092182f764f8a",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "PolarsBuckarooWidget(buckaroo_options={'sampled': ['random'], 'auto_clean': ['aggressive', 'conservative'], 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fileLoc = r\"C:\\Users\\Joshh\\Projects\\Stocks\\Data\\sentiment_data_FINAL.parquet\"\n",
    "df2 = pl.read_parquet(fileLoc)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf19630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename',\n",
       " 'title',\n",
       " 'text',\n",
       " 'publication_date',\n",
       " 'keywords',\n",
       " 'authors',\n",
       " 'title_sentiment_positive',\n",
       " 'title_sentiment_negative',\n",
       " 'title_sentiment_neutral',\n",
       " 'title_sentiment_compound',\n",
       " 'text_sentiment_positive',\n",
       " 'text_sentiment_negative',\n",
       " 'text_sentiment_neutral',\n",
       " 'text_sentiment_compound',\n",
       " 'combined_sentiment_positive',\n",
       " 'combined_sentiment_negative',\n",
       " 'combined_sentiment_neutral',\n",
       " 'combined_sentiment_compound',\n",
       " 'organizations',\n",
       " 'jse_symbols',\n",
       " 'entity_specific_sentiments']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc315312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Enhanced Stock-Sentiment Integration Pipeline ===\n",
      "Loading stock data...\n",
      "Loaded stock data: 156,385 records for 99 symbols\n",
      "Loading and processing sentiment data...\n",
      "Schema: Schema({'filename': String, 'title': String, 'text': String, 'publication_date': Date, 'keywords': List(String), 'authors': List(String), 'title_sentiment_positive': Float64, 'title_sentiment_negative': Float64, 'title_sentiment_neutral': Float64, 'title_sentiment_compound': Float64, 'text_sentiment_positive': Float64, 'text_sentiment_negative': Float64, 'text_sentiment_neutral': Float64, 'text_sentiment_compound': Float64, 'combined_sentiment_positive': Float64, 'combined_sentiment_negative': Float64, 'combined_sentiment_neutral': Float64, 'combined_sentiment_compound': Float64, 'organizations': List(String), 'jse_symbols': List(String), 'entity_specific_sentiments': Struct({'the Jamaica Stock Exchange': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'the Investor’s Choice': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Access Financial': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'AMG Packaging': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Cargo Handlers': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Caribbean Cream': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Caribbean Producers': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Express Catering': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Accident': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Honey Bun': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'ISP Finance': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Jamaican Teas': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Jetcon Corporation': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Knutsford Express': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Lasco Distributors': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Lasco Financial': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Lasco Manufacturing': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Paramount Trading': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Stationery': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Office': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'tTech': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64}), 'Derrimon Trading': Struct({'positive': Float64, 'negative': Float64, 'neutral': Float64, 'compound': Float64})})})\n",
      "Creating market sentiment indicators...\n",
      "Processing entity-specific sentiments...\n",
      "Aggregating company-specific sentiment features...\n",
      "Calculating temporal sentiment features...\n",
      "Calculating stock technical indicators...\n",
      "Calculating technical indicators and signals...\n",
      "Calculating daily VWAP...\n",
      "Merging stock and company sentiment data...\n",
      "Adding market sentiment indicators...\n",
      "Calculating advanced interaction features...\n",
      "\n",
      "--- Final Data Schema ---\n",
      "- date: Date\n",
      "- symbol: String\n",
      "- high_price: Float64\n",
      "- low_price: Float64\n",
      "- closing_price: Float64\n",
      "- opening_price: Float64\n",
      "- volume: Float64\n",
      "- returns: Float64\n",
      "- intraday_return: Float64\n",
      "- daily_range: Float64\n",
      "- sma_20: Float64\n",
      "- sma_50: Float64\n",
      "- volume_ma10: Float64\n",
      "- volume_ma20: Float64\n",
      "- macd: Float64\n",
      "- rsi_14: Float64\n",
      "- signal_line: Float64\n",
      "- volatility_10d: Float64\n",
      "- volatility_20d: Float64\n",
      "- volume_ratio: Float64\n",
      "- macd_histogram: Float64\n",
      "- ma_buy_signal: Boolean\n",
      "- ma_sell_signal: Boolean\n",
      "- macd_buy_signal: Boolean\n",
      "- macd_sell_signal: Boolean\n",
      "- rsi_buy_signal: Boolean\n",
      "- rsi_sell_signal: Boolean\n",
      "- combined_buy_signal: Boolean\n",
      "- combined_sell_signal: Boolean\n",
      "- article_count: UInt32\n",
      "- avg_sentiment: Float64\n",
      "- entity_specific_sentiment: Float64\n",
      "- avg_positive: Float64\n",
      "- avg_negative: Float64\n",
      "- avg_neutral: Float64\n",
      "- entity_avg_positive: Float64\n",
      "- entity_avg_negative: Float64\n",
      "- entity_avg_neutral: Float64\n",
      "- sentiment_volatility: Float64\n",
      "- entity_sentiment_volatility: Float64\n",
      "- min_sentiment: Float64\n",
      "- max_sentiment: Float64\n",
      "- entity_min_sentiment: Float64\n",
      "- entity_max_sentiment: Float64\n",
      "- headline_bias: Float64\n",
      "- headline_text_divergence: Float64\n",
      "- entity_general_divergence: Float64\n",
      "- sentiment_concentration: Float64\n",
      "- volume_weighted_sentiment: Float64\n",
      "- sentiment_momentum: Float64\n",
      "- entity_sentiment_momentum: Float64\n",
      "- sentiment_3d_ma: Float64\n",
      "- sentiment_7d_ma: Float64\n",
      "- entity_sentiment_3d_ma: Float64\n",
      "- entity_sentiment_7d_ma: Float64\n",
      "- sentiment_7d_volatility: Float64\n",
      "- entity_sentiment_7d_volatility: Float64\n",
      "- news_volume_momentum: Float64\n",
      "- news_volume_7d_ma: Float64\n",
      "- market_news_count: UInt32\n",
      "- market_sentiment: Float64\n",
      "- market_sentiment_volatility: Float64\n",
      "- market_positive: Float64\n",
      "- market_negative: Float64\n",
      "- market_neutral: Float64\n",
      "- volume_weighted_market_sentiment: Float64\n",
      "- sentiment_returns_interaction: Float64\n",
      "- entity_sentiment_returns_interaction: Float64\n",
      "- market_sentiment_returns_interaction: Float64\n",
      "- sentiment_volume_interaction: Float64\n",
      "- entity_sentiment_volume_interaction: Float64\n",
      "- market_sentiment_volume_interaction: Float64\n",
      "- sentiment_volatility_interaction: Float64\n",
      "- entity_sentiment_volatility_interaction: Float64\n",
      "- market_sentiment_volatility_interaction: Float64\n",
      "- sentiment_momentum_returns_interaction: Float64\n",
      "- entity_sentiment_momentum_returns_interaction: Float64\n",
      "- news_volume_trading_interaction: Float64\n",
      "- market_news_volume_interaction: Float64\n",
      "- relative_sentiment_vs_market: Float64\n",
      "- entity_relative_sentiment_vs_market: Float64\n",
      "- sentiment_signal_strength: Float64\n",
      "- entity_sentiment_signal_strength: Float64\n",
      "- combined_sentiment_score: Float64\n",
      "\n",
      "Final dataset shape: (156385, 84)\n",
      "Date range: 2017-01-03 to 2024-12-24\n",
      "Unique symbols: 99\n",
      "\n",
      "--- Sample Output ---\n",
      "shape: (10, 9)\n",
      "┌────────┬────────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ date       ┆ closing_pr ┆ returns   ┆ … ┆ entity_sp ┆ market_se ┆ sentiment ┆ combined_ │\n",
      "│ ---    ┆ ---        ┆ ice        ┆ ---       ┆   ┆ ecific_se ┆ ntiment   ┆ _signal_s ┆ sentiment │\n",
      "│ str    ┆ date       ┆ ---        ┆ f64       ┆   ┆ ntiment   ┆ ---       ┆ trength   ┆ _score    │\n",
      "│        ┆            ┆ f64        ┆           ┆   ┆ ---       ┆ f64       ┆ ---       ┆ ---       │\n",
      "│        ┆            ┆            ┆           ┆   ┆ f64       ┆           ┆ f64       ┆ f64       │\n",
      "╞════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 138SL  ┆ 2017-01-03 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-04 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ -0.517174 ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-05 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-06 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-09 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-10 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-11 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-12 ┆ 4.52       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-13 ┆ 4.5        ┆ -0.004425 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "│ 138SL  ┆ 2017-01-16 ┆ 4.5        ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
      "└────────┴────────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "Data successfully saved to:\n",
      "- Main dataset: C:/Users/Joshh/Projects/Stocks/Data/Integrated\\enhanced_integrated_stock_sentiment_features.parquet\n",
      "- Market sentiment: C:/Users/Joshh/Projects/Stocks/Data/Integrated\\market_sentiment_indicators.parquet\n",
      "\n",
      "=== Pipeline Complete ===\n"
     ]
    }
   ],
   "source": [
    "# Enhanced stock and sentiment integration script with entity-specific sentiment, market sentiment, and temporal features\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from data_loader import DataLoader\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "STOCK_DATA_PATH = \"C:/Users/Joshh/Projects/Stocks/Data/stock_data.parquet\"\n",
    "SENTIMENT_DATA_PATH = \"C:/Users/Joshh/Projects/Stocks/Data/sentiment_data_FINAL.parquet\"\n",
    "OUTPUT_DIR = \"C:/Users/Joshh/Projects/Stocks/Data/Integrated\"\n",
    "\n",
    "# Market sentiment keywords for overall market indicators\n",
    "MARKET_KEYWORDS = ['trading', 'market', 'stocks', 'securities', 'exchange', 'index', 'volume', 'shares']\n",
    "\n",
    "# --- Loaders ---\n",
    "def load_stock_data(file_path: str) -> pl.DataFrame:\n",
    "    print(\"Loading stock data...\")\n",
    "    loader = DataLoader()\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        trade_date as date,\n",
    "        clean_symbol as symbol,\n",
    "        daily_range_high as high_price,\n",
    "        daily_range_low as low_price,\n",
    "        closing_price,\n",
    "        closing_price + price_change as opening_price,\n",
    "        volume\n",
    "    FROM old_trade_data TD\n",
    "    LEFT JOIN jse_database.instruments I ON (TD.CLEAN_symbol = I.symbol AND TD.CURRENCY = I.CURRENCY)\n",
    "    WHERE trade_date BETWEEN :start_date AND :end_date\n",
    "      AND I.TYPE = 'ORDINARY'\n",
    "      AND TD.CURRENCY = 'JMD'\n",
    "    ORDER BY trade_date ASC, clean_symbol ASC\n",
    "    \"\"\"\n",
    "\n",
    "    df = loader.fetch_data(query=query, start_date='2017-01-01', end_date='2025-03-31')\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"date\").dt.date(),\n",
    "        pl.col(\"symbol\").cast(pl.Utf8),\n",
    "        pl.col(\"high_price\").cast(pl.Float64),\n",
    "        pl.col(\"low_price\").cast(pl.Float64),\n",
    "        pl.col(\"closing_price\").cast(pl.Float64),\n",
    "        pl.col(\"opening_price\").cast(pl.Float64),\n",
    "        pl.col(\"volume\").cast(pl.Float64).fill_null(0)\n",
    "    ])\n",
    "\n",
    "    print(f\"Loaded stock data: {df.height:,} records for {df.select('symbol').n_unique()} symbols\")\n",
    "    return df.sort([\"symbol\", \"date\"])\n",
    "\n",
    "def load_sentiment_data(file_path: str) -> Tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    print(\"Loading and processing sentiment data...\")\n",
    "    \n",
    "    # Load raw sentiment data and inspect the structure\n",
    "    df = pl.read_parquet(file_path)\n",
    "    print(f\"Schema: {df.schema}\")\n",
    "    \n",
    "    # Handle the data based on actual structure\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"publication_date\").alias(\"date\"),\n",
    "        pl.col(\"jse_symbols\").cast(pl.List(pl.Utf8))\n",
    "        # Don't cast entity_specific_sentiments since it's already structured\n",
    "    ])\n",
    "\n",
    "    print(\"Creating market sentiment indicators...\")\n",
    "    # Create market sentiment specifically from articles where JSE is mentioned as a symbol\n",
    "    market_sentiment = df.filter(\n",
    "        pl.col(\"jse_symbols\").list.contains(\"JSE\")\n",
    "    ).group_by(\"date\").agg([\n",
    "        pl.count(\"title\").alias(\"market_news_count\"),\n",
    "        pl.col(\"combined_sentiment_compound\").mean().alias(\"market_sentiment\"),\n",
    "        pl.col(\"combined_sentiment_compound\").std().fill_null(0).alias(\"market_sentiment_volatility\"),\n",
    "        pl.col(\"combined_sentiment_positive\").mean().alias(\"market_positive\"),\n",
    "        pl.col(\"combined_sentiment_negative\").mean().alias(\"market_negative\"),\n",
    "        pl.col(\"combined_sentiment_neutral\").mean().alias(\"market_neutral\"),\n",
    "        # Volume-weighted sentiment (more articles = stronger signal)\n",
    "        (pl.col(\"combined_sentiment_compound\") * pl.count(\"title\")).sum().alias(\"volume_weighted_market_sentiment\")\n",
    "    ]).with_columns([\n",
    "        # Normalize volume-weighted sentiment\n",
    "        (pl.col(\"volume_weighted_market_sentiment\") / pl.col(\"market_news_count\")).alias(\"volume_weighted_market_sentiment\")\n",
    "    ])\n",
    "\n",
    "    print(\"Processing entity-specific sentiments...\")\n",
    "    # Explode by symbols and process entity-specific sentiments (exclude JSE for individual stock analysis)\n",
    "    df_exploded = df.select([\n",
    "        \"date\", \"title\", \"text\", \"authors\",\n",
    "        \"title_sentiment_compound\", \"text_sentiment_compound\", \"combined_sentiment_compound\",\n",
    "        'combined_sentiment_positive', 'combined_sentiment_negative', 'combined_sentiment_neutral',\n",
    "        \"entity_specific_sentiments\", \"jse_symbols\"\n",
    "    ]).explode(\"jse_symbols\").filter(\n",
    "        pl.col(\"jse_symbols\").is_not_null() & \n",
    "        (pl.col(\"jse_symbols\") != \"\") & \n",
    "        (pl.col(\"jse_symbols\") != \"JSE\")  # Exclude JSE from individual stock sentiment\n",
    "    )\n",
    "\n",
    "    # For now, let's use the combined sentiment as entity sentiment since the struct parsing is complex\n",
    "    # We'll add entity-specific features in the next iteration\n",
    "    df_with_entity = df_exploded.with_columns([\n",
    "        # Use combined sentiment as proxy for entity sentiment for now\n",
    "        pl.col(\"combined_sentiment_positive\").alias(\"entity_positive\"),\n",
    "        pl.col(\"combined_sentiment_negative\").alias(\"entity_negative\"),\n",
    "        pl.col(\"combined_sentiment_neutral\").alias(\"entity_neutral\"),\n",
    "        pl.col(\"combined_sentiment_compound\").alias(\"entity_compound\")\n",
    "    ])\n",
    "\n",
    "    print(\"Aggregating company-specific sentiment features...\")\n",
    "    # Aggregate by date and symbol with enhanced features\n",
    "    company_sentiment = df_with_entity.group_by([\"date\", \"jse_symbols\"]).agg([\n",
    "        # Basic counts and averages\n",
    "        pl.count(\"title\").alias(\"article_count\"),\n",
    "        pl.col(\"combined_sentiment_compound\").mean().alias(\"avg_sentiment\"),\n",
    "        pl.col(\"entity_compound\").mean().alias(\"entity_specific_sentiment\"),\n",
    "        \n",
    "        # Sentiment distributions\n",
    "        pl.col(\"combined_sentiment_positive\").mean().alias(\"avg_positive\"),\n",
    "        pl.col(\"combined_sentiment_negative\").mean().alias(\"avg_negative\"),\n",
    "        pl.col(\"combined_sentiment_neutral\").mean().alias(\"avg_neutral\"),\n",
    "        pl.col(\"entity_positive\").mean().alias(\"entity_avg_positive\"),\n",
    "        pl.col(\"entity_negative\").mean().alias(\"entity_avg_negative\"),\n",
    "        pl.col(\"entity_neutral\").mean().alias(\"entity_avg_neutral\"),\n",
    "        \n",
    "        # Sentiment variability and extremes\n",
    "        pl.col(\"combined_sentiment_compound\").std().fill_null(0).alias(\"sentiment_volatility\"),\n",
    "        pl.col(\"entity_compound\").std().fill_null(0).alias(\"entity_sentiment_volatility\"),\n",
    "        pl.col(\"combined_sentiment_compound\").min().alias(\"min_sentiment\"),\n",
    "        pl.col(\"combined_sentiment_compound\").max().alias(\"max_sentiment\"),\n",
    "        pl.col(\"entity_compound\").min().alias(\"entity_min_sentiment\"),\n",
    "        pl.col(\"entity_compound\").max().alias(\"entity_max_sentiment\"),\n",
    "        \n",
    "        # Title vs text sentiment divergence\n",
    "        (pl.col(\"title_sentiment_compound\") - pl.col(\"text_sentiment_compound\")).mean().alias(\"headline_bias\"),\n",
    "        (pl.col(\"title_sentiment_compound\") - pl.col(\"text_sentiment_compound\")).abs().mean().alias(\"headline_text_divergence\"),\n",
    "        \n",
    "        # Entity vs general sentiment divergence\n",
    "        (pl.col(\"entity_compound\") - pl.col(\"combined_sentiment_compound\")).mean().alias(\"entity_general_divergence\"),\n",
    "        \n",
    "        # Sentiment concentration (how consistent sentiment is)\n",
    "        pl.col(\"combined_sentiment_compound\").map_elements(\n",
    "            lambda x: 1.0 - (len(set(x.to_list())) / len(x.to_list())) if len(x) > 1 else 1.0,\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(\"sentiment_concentration\"),\n",
    "        \n",
    "        # Volume-weighted sentiment for this company\n",
    "        (pl.col(\"combined_sentiment_compound\") * pl.count(\"title\")).sum().alias(\"volume_weighted_sentiment\")\n",
    "    ]).with_columns([\n",
    "        # Normalize volume-weighted sentiment\n",
    "        (pl.col(\"volume_weighted_sentiment\") / pl.col(\"article_count\")).alias(\"volume_weighted_sentiment\")\n",
    "    ]).sort([\"jse_symbols\", \"date\"])\n",
    "\n",
    "    # Add temporal sentiment features\n",
    "    print(\"Calculating temporal sentiment features...\")\n",
    "    company_sentiment = company_sentiment.with_columns([\n",
    "        # Sentiment momentum (rate of change)\n",
    "        pl.col(\"avg_sentiment\").diff().over(\"jse_symbols\").alias(\"sentiment_momentum\"),\n",
    "        pl.col(\"entity_specific_sentiment\").diff().over(\"jse_symbols\").alias(\"entity_sentiment_momentum\"),\n",
    "        \n",
    "        # Rolling sentiment averages\n",
    "        pl.col(\"avg_sentiment\").rolling_mean(3).over(\"jse_symbols\").alias(\"sentiment_3d_ma\"),\n",
    "        pl.col(\"avg_sentiment\").rolling_mean(7).over(\"jse_symbols\").alias(\"sentiment_7d_ma\"),\n",
    "        pl.col(\"entity_specific_sentiment\").rolling_mean(3).over(\"jse_symbols\").alias(\"entity_sentiment_3d_ma\"),\n",
    "        pl.col(\"entity_specific_sentiment\").rolling_mean(7).over(\"jse_symbols\").alias(\"entity_sentiment_7d_ma\"),\n",
    "        \n",
    "        # Rolling sentiment volatility\n",
    "        pl.col(\"avg_sentiment\").rolling_std(7).over(\"jse_symbols\").alias(\"sentiment_7d_volatility\"),\n",
    "        pl.col(\"entity_specific_sentiment\").rolling_std(7).over(\"jse_symbols\").alias(\"entity_sentiment_7d_volatility\"),\n",
    "        \n",
    "        # Article volume momentum\n",
    "        pl.col(\"article_count\").diff().over(\"jse_symbols\").alias(\"news_volume_momentum\"),\n",
    "        pl.col(\"article_count\").rolling_mean(7).over(\"jse_symbols\").alias(\"news_volume_7d_ma\")\n",
    "    ])\n",
    "\n",
    "    return company_sentiment.rename({\"jse_symbols\": \"symbol\"}), market_sentiment\n",
    "\n",
    "# --- Technical Indicators ---\n",
    "def calculate_vwap(df: pl.DataFrame, symbol_col: str = \"symbol\") -> pl.DataFrame:\n",
    "    print(\"Calculating daily VWAP...\")\n",
    "    return df.with_columns([\n",
    "        ((pl.col(\"high_price\") + pl.col(\"low_price\") + pl.col(\"closing_price\")) / 3 * pl.col(\"volume\")).sum().over([symbol_col, \"date\"]) / \n",
    "        pl.col(\"volume\").sum().over([symbol_col, \"date\"]).alias(\"vwap\")\n",
    "    ])\n",
    "\n",
    "def calculate_technical_indicators(df: pl.DataFrame, symbol_col: str = \"symbol\") -> pl.DataFrame:\n",
    "    print(\"Calculating technical indicators and signals...\")\n",
    "    df = df.sort([symbol_col, \"date\"])\n",
    "    \n",
    "    # Step 1: Calculate basic price movements and EMAs\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"closing_price\").pct_change().over(symbol_col).fill_null(0).alias(\"returns\"),\n",
    "        pl.col(\"closing_price\").diff().over(symbol_col).alias(\"price_diff\"),\n",
    "        pl.col(\"closing_price\").ewm_mean(span=12).over(symbol_col).alias(\"ema12\"),\n",
    "        pl.col(\"closing_price\").ewm_mean(span=26).over(symbol_col).alias(\"ema26\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 2: Calculate RSI components\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col(\"price_diff\") > 0)\n",
    "        .then(pl.col(\"price_diff\"))\n",
    "        .otherwise(0)\n",
    "        .rolling_mean(14).over(symbol_col)\n",
    "        .alias(\"avg_gain\"),\n",
    "        \n",
    "        pl.when(pl.col(\"price_diff\") < 0)\n",
    "        .then(-pl.col(\"price_diff\"))\n",
    "        .otherwise(0)\n",
    "        .rolling_mean(14).over(symbol_col)\n",
    "        .alias(\"avg_loss\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 3: Calculate derived indicators\n",
    "    df = df.with_columns([\n",
    "        # Basic returns and ranges\n",
    "        ((pl.col(\"closing_price\") - pl.col(\"opening_price\")) / \n",
    "         pl.when(pl.col(\"opening_price\") == 0).then(1).otherwise(pl.col(\"opening_price\"))\n",
    "        ).alias(\"intraday_return\"),\n",
    "        \n",
    "        ((pl.col(\"high_price\") - pl.col(\"low_price\")) / \n",
    "         pl.when(pl.col(\"low_price\") == 0).then(1).otherwise(pl.col(\"low_price\"))\n",
    "        ).alias(\"daily_range\"),\n",
    "        \n",
    "        # Moving averages\n",
    "        pl.col(\"closing_price\").rolling_mean(20).over(symbol_col).alias(\"sma_20\"),\n",
    "        pl.col(\"closing_price\").rolling_mean(50).over(symbol_col).alias(\"sma_50\"),\n",
    "        pl.col(\"volume\").rolling_mean(10).over(symbol_col).alias(\"volume_ma10\"),\n",
    "        pl.col(\"volume\").rolling_mean(20).over(symbol_col).alias(\"volume_ma20\"),\n",
    "        \n",
    "        # MACD\n",
    "        (pl.col(\"ema12\") - pl.col(\"ema26\")).alias(\"macd\"),\n",
    "        \n",
    "        # RSI\n",
    "        pl.when(pl.col(\"avg_loss\") == 0)\n",
    "        .then(100)\n",
    "        .otherwise(100 - (100 / (1 + pl.col(\"avg_gain\") / pl.col(\"avg_loss\"))))\n",
    "        .fill_null(50)\n",
    "        .alias(\"rsi_14\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Calculate MACD signal line and dependent indicators\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"macd\").ewm_mean(span=9).over(symbol_col).alias(\"signal_line\"),\n",
    "        pl.col(\"returns\").rolling_std(10).over(symbol_col).fill_null(0).alias(\"volatility_10d\"),\n",
    "        pl.col(\"returns\").rolling_std(20).over(symbol_col).fill_null(0).alias(\"volatility_20d\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 5: Calculate volume ratio and MACD histogram\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"volume\") / \n",
    "         pl.when(pl.col(\"volume_ma20\") == 0).then(1).otherwise(pl.col(\"volume_ma20\"))\n",
    "        ).alias(\"volume_ratio\"),\n",
    "        (pl.col(\"macd\") - pl.col(\"signal_line\")).alias(\"macd_histogram\")\n",
    "    ])\n",
    "\n",
    "    # Step 6: Calculate VWAP\n",
    "    df = calculate_vwap(df, symbol_col)\n",
    "\n",
    "    # Step 7: Generate trading signals\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"sma_20\") > pl.col(\"sma_50\")).alias(\"ma_buy_signal\"),\n",
    "        (pl.col(\"sma_20\") < pl.col(\"sma_50\")).alias(\"ma_sell_signal\"),\n",
    "        (pl.col(\"macd\") > pl.col(\"signal_line\")).alias(\"macd_buy_signal\"),\n",
    "        (pl.col(\"macd\") < pl.col(\"signal_line\")).alias(\"macd_sell_signal\"),\n",
    "        (pl.col(\"rsi_14\") < 30).alias(\"rsi_buy_signal\"),\n",
    "        (pl.col(\"rsi_14\") > 70).alias(\"rsi_sell_signal\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 8: Combined signals\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"ma_buy_signal\") & pl.col(\"macd_buy_signal\")).alias(\"combined_buy_signal\"),\n",
    "        (pl.col(\"ma_sell_signal\") & pl.col(\"macd_sell_signal\")).alias(\"combined_sell_signal\")\n",
    "    ])\n",
    "    \n",
    "    # Clean up intermediate columns\n",
    "    df = df.drop([\"price_diff\", \"avg_gain\", \"avg_loss\", \"ema12\", \"ema26\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Integration ---\n",
    "def integrate_data(stock_df: pl.DataFrame, sentiment_df: pl.DataFrame, market_sentiment_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    print(\"Calculating stock technical indicators...\")\n",
    "    stock_with_features = calculate_technical_indicators(stock_df)\n",
    "    \n",
    "    print(\"Merging stock and company sentiment data...\")\n",
    "    # Join company-specific sentiment\n",
    "    merged_df = stock_with_features.join(sentiment_df, on=[\"date\", \"symbol\"], how=\"left\")\n",
    "\n",
    "    # Fill missing sentiment values with neutral defaults\n",
    "    sentiment_fill = {\n",
    "        \"article_count\": 0, \"avg_sentiment\": 0.0, \"entity_specific_sentiment\": 0.0,\n",
    "        \"sentiment_volatility\": 0.0, \"entity_sentiment_volatility\": 0.0,\n",
    "        \"min_sentiment\": 0.0, \"max_sentiment\": 0.0, \n",
    "        \"entity_min_sentiment\": 0.0, \"entity_max_sentiment\": 0.0,\n",
    "        \"avg_positive\": 0.33, \"avg_negative\": 0.33, \"avg_neutral\": 0.34,\n",
    "        \"entity_avg_positive\": 0.33, \"entity_avg_negative\": 0.33, \"entity_avg_neutral\": 0.34,\n",
    "        \"headline_bias\": 0.0, \"headline_text_divergence\": 0.0, \"entity_general_divergence\": 0.0,\n",
    "        \"sentiment_concentration\": 0.0, \"volume_weighted_sentiment\": 0.0,\n",
    "        \"sentiment_momentum\": 0.0, \"entity_sentiment_momentum\": 0.0,\n",
    "        \"sentiment_3d_ma\": 0.0, \"sentiment_7d_ma\": 0.0,\n",
    "        \"entity_sentiment_3d_ma\": 0.0, \"entity_sentiment_7d_ma\": 0.0,\n",
    "        \"sentiment_7d_volatility\": 0.0, \"entity_sentiment_7d_volatility\": 0.0,\n",
    "        \"news_volume_momentum\": 0.0, \"news_volume_7d_ma\": 0.0\n",
    "    }\n",
    "    \n",
    "    for col, val in sentiment_fill.items():\n",
    "        if col in merged_df.columns:\n",
    "            merged_df = merged_df.with_columns(pl.col(col).fill_null(val))\n",
    "\n",
    "    print(\"Adding market sentiment indicators...\")\n",
    "    # Join market sentiment\n",
    "    merged_df = merged_df.join(market_sentiment_df, on=\"date\", how=\"left\")\n",
    "    \n",
    "    # Fill missing market sentiment\n",
    "    market_fill = {\n",
    "        \"market_news_count\": 0, \"market_sentiment\": 0.0, \"market_sentiment_volatility\": 0.0,\n",
    "        \"market_positive\": 0.33, \"market_negative\": 0.33, \"market_neutral\": 0.34,\n",
    "        \"volume_weighted_market_sentiment\": 0.0\n",
    "    }\n",
    "    \n",
    "    for col, val in market_fill.items():\n",
    "        if col in merged_df.columns:\n",
    "            merged_df = merged_df.with_columns(pl.col(col).fill_null(val))\n",
    "\n",
    "    print(\"Calculating advanced interaction features...\")\n",
    "    merged_df = merged_df.with_columns([\n",
    "        # Sentiment-returns interactions\n",
    "        (pl.col(\"avg_sentiment\") * pl.col(\"returns\")).alias(\"sentiment_returns_interaction\"),\n",
    "        (pl.col(\"entity_specific_sentiment\") * pl.col(\"returns\")).alias(\"entity_sentiment_returns_interaction\"),\n",
    "        (pl.col(\"market_sentiment\") * pl.col(\"returns\")).alias(\"market_sentiment_returns_interaction\"),\n",
    "        \n",
    "        # Sentiment-volume interactions\n",
    "        (pl.col(\"avg_sentiment\") * pl.col(\"volume_ratio\")).alias(\"sentiment_volume_interaction\"),\n",
    "        (pl.col(\"entity_specific_sentiment\") * pl.col(\"volume_ratio\")).alias(\"entity_sentiment_volume_interaction\"),\n",
    "        (pl.col(\"market_sentiment\") * pl.col(\"volume_ratio\")).alias(\"market_sentiment_volume_interaction\"),\n",
    "        \n",
    "        # Sentiment-volatility interactions\n",
    "        (pl.col(\"sentiment_volatility\") * pl.col(\"volatility_10d\")).alias(\"sentiment_volatility_interaction\"),\n",
    "        (pl.col(\"entity_sentiment_volatility\") * pl.col(\"volatility_10d\")).alias(\"entity_sentiment_volatility_interaction\"),\n",
    "        (pl.col(\"market_sentiment_volatility\") * pl.col(\"volatility_10d\")).alias(\"market_sentiment_volatility_interaction\"),\n",
    "        \n",
    "        # Sentiment momentum interactions\n",
    "        (pl.col(\"sentiment_momentum\") * pl.col(\"returns\")).alias(\"sentiment_momentum_returns_interaction\"),\n",
    "        (pl.col(\"entity_sentiment_momentum\") * pl.col(\"returns\")).alias(\"entity_sentiment_momentum_returns_interaction\"),\n",
    "        \n",
    "        # News volume effects\n",
    "        (pl.col(\"article_count\") * pl.col(\"volume_ratio\")).alias(\"news_volume_trading_interaction\"),\n",
    "        (pl.col(\"market_news_count\") * pl.col(\"volume_ratio\")).alias(\"market_news_volume_interaction\"),\n",
    "        \n",
    "        # Relative sentiment vs market\n",
    "        (pl.col(\"avg_sentiment\") - pl.col(\"market_sentiment\")).alias(\"relative_sentiment_vs_market\"),\n",
    "        (pl.col(\"entity_specific_sentiment\") - pl.col(\"market_sentiment\")).alias(\"entity_relative_sentiment_vs_market\"),\n",
    "        \n",
    "        # Sentiment signal strength\n",
    "        (pl.col(\"article_count\") * pl.col(\"avg_sentiment\").abs()).alias(\"sentiment_signal_strength\"),\n",
    "        (pl.col(\"article_count\") * pl.col(\"entity_specific_sentiment\").abs()).alias(\"entity_sentiment_signal_strength\"),\n",
    "        \n",
    "        # Combined sentiment score (weighted average of general and entity-specific)\n",
    "        (0.6 * pl.col(\"entity_specific_sentiment\") + 0.4 * pl.col(\"avg_sentiment\")).alias(\"combined_sentiment_score\")\n",
    "    ])\n",
    "\n",
    "    return merged_df.sort([\"symbol\", \"date\"])\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Enhanced Stock-Sentiment Integration Pipeline ===\")\n",
    "    \n",
    "    # Load data\n",
    "    stock_df = load_stock_data(STOCK_DATA_PATH)\n",
    "    sentiment_df, market_sentiment_df = load_sentiment_data(SENTIMENT_DATA_PATH)\n",
    "    \n",
    "    # Integrate all data\n",
    "    integrated_df = integrate_data(stock_df, sentiment_df, market_sentiment_df)\n",
    "\n",
    "    print(\"\\n--- Final Data Schema ---\")\n",
    "    for col, dtype in integrated_df.schema.items():\n",
    "        print(f\"- {col}: {dtype}\")\n",
    "\n",
    "    print(f\"\\nFinal dataset shape: {integrated_df.shape}\")\n",
    "    print(f\"Date range: {integrated_df.select('date').min().item()} to {integrated_df.select('date').max().item()}\")\n",
    "    print(f\"Unique symbols: {integrated_df.select('symbol').n_unique()}\")\n",
    "    \n",
    "    # Sample output\n",
    "    print(\"\\n--- Sample Output ---\")\n",
    "    sample_cols = ['symbol', 'date', 'closing_price', 'returns', 'avg_sentiment', 'entity_specific_sentiment', \n",
    "                   'market_sentiment', 'sentiment_signal_strength', 'combined_sentiment_score']\n",
    "    print(integrated_df.select(sample_cols).head(10))\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    output_file = os.path.join(OUTPUT_DIR, \"enhanced_integrated_stock_sentiment_features.parquet\")\n",
    "    integrated_df.write_parquet(output_file)\n",
    "    \n",
    "    # Save market sentiment separately for analysis\n",
    "    market_output_file = os.path.join(OUTPUT_DIR, \"market_sentiment_indicators.parquet\")\n",
    "    market_sentiment_df.write_parquet(market_output_file)\n",
    "    \n",
    "    print(f\"\\nData successfully saved to:\")\n",
    "    print(f\"- Main dataset: {output_file}\")\n",
    "    print(f\"- Market sentiment: {market_output_file}\")\n",
    "    print(\"\\n=== Pipeline Complete ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
